<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Carles Hernandez-Ferrer</title>
    <link>http://212.71.254.23/blog/</link>
    <description>Recent content in Blogs on Carles Hernandez-Ferrer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Fri, 03 Mar 2023 00:00:00 +0200</lastBuildDate><atom:link href="http://212.71.254.23/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using XGBoost models with python&#39;s Flower</title>
      <link>http://212.71.254.23/blog/using-xgboost-models-with-python-flower/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/using-xgboost-models-with-python-flower/</guid>
      <description>The idea here is to use Flower to create a federated infrastructure to run an XGBClassifier in a series of datasets located in exclusive-access nodes.
This means that a central server, the one that will connect and aggregate the models, is required as well as the local client, the one training the models on the exclusive-access datasets.
Client code The code assumes that there is an environment-variables called DATA_PATH pointing to a CSV-file having the data to be used.</description>
    </item>
    
    <item>
      <title>Some &#39;must&#39; methods for JavaScript array</title>
      <link>http://212.71.254.23/blog/must-javascript-array/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/must-javascript-array/</guid>
      <description>I recently been working a lot with JavaScript and I missed some methods for the JavaScript&amp;rsquo;s array.
First I missed three core methods related of the content of the array. A method to get the unique elements in the array (arr.unique()), a method that returns the number of occurrences of a given element (arr.count(val)), and a method that returns some sort of table with the number of occurrences of each unique element in the array - see this one as a combination of the previous two - (arr.</description>
    </item>
    
    <item>
      <title>Code for Care (Hackathon)</title>
      <link>http://212.71.254.23/blog/code-4-care-hackathon/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/code-4-care-hackathon/</guid>
      <description>On Saturday, June 1st 2019, I attended the hackathon Code for Care organized by Humana Experience Center, at the District Hall (Boston, MA).
The goal of that hackathon was to build a digital software to help [not-necessary] elderly to manage their medications, taking special attention to those individuals with comorbidities (the simultaneous presence of two chronic diseases or conditions in the same individual).
There was no limitation in type of software nor in technology we could use for the development, although we were encouraged to use the FDAâ€™s free drug data API, that provides access to data like adverse events, product labeling, and a full directory of all NDCs (National Drug Codes).</description>
    </item>
    
    <item>
      <title>Exploiting XML data from Human Metabolome Data Base</title>
      <link>http://212.71.254.23/blog/hmdb-xml-to-csv/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/hmdb-xml-to-csv/</guid>
      <description>I am currently working on a project where I need to annotate exogenous chemicals measured in plasma using GC-MS/MS to the Human Metabolome Data Base (HMDB) and to the Toxin and Toxin Target Database (T3DB).
T3DB offers a series of downloadable resources that can be easy integrated into R as a CSV file after being parsed using bash. On the other hand, HMDB only offers XML sources that are to heavy to be parsed using the XML R package in my laptop.</description>
    </item>
    
    <item>
      <title>Annotating KEGG compounds to pathway</title>
      <link>http://212.71.254.23/blog/annotating-kegg-compounds-to-pathway/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/annotating-kegg-compounds-to-pathway/</guid>
      <description>To annotate a list of KEGG compounds to the KEGG pathways where they are involved I used the R package KEGGREST from Bioconductor.
library(KEGGREST) So, having a list of KEGG compounds saved in a character vector like kegg_compounds, we use the method keggGet in batches of maximum 10 compounds to annotate them.
The following (rudimentary) code, queries the database in batches of ten compounds fiddling a list (pathways) where it creates an entry per pathway and updates the field compounds with the compounds from kegg_compounds for each pathway.</description>
    </item>
    
    <item>
      <title>Exploring public NHANES data using Rcupcake</title>
      <link>http://212.71.254.23/blog/exploring-public-nhanes-data-using-rcupcake/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/exploring-public-nhanes-data-using-rcupcake/</guid>
      <description>The Rcupcake package contains functions to query different databases through the BD2K RESTful API. BD2K RESTful API is an interface that provides access to different data sources, making easier data accessibility, analysis reproducibility and scalability.
The package is installed via devtools using it&amp;rsquo;s GitHub URL (hms-dbmi/Rcupcake) or following their guide (also in GiHub - here).
library( Rcupcake ) library( knitr ) library( stringr ) opts_chunk$set( fig.path=&amp;#39;Figs/&amp;#39;, echo=TRUE, warning=FALSE, message=FALSE, cache=FALSE ) Rcupcake package follows a four-step process to retrieve the data from a database:</description>
    </item>
    
    <item>
      <title>Cross-referencing between different files with LaTeX</title>
      <link>http://212.71.254.23/blog/cross-referencing-between-different-files-with-latex/</link>
      <pubDate>Thu, 28 Sep 2017 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/cross-referencing-between-different-files-with-latex/</guid>
      <description>Sometimes I want to refer labels I placed in external .tex files. I mean, I want o refer (using the command \ref) a \label from a .tex file I created in another project.
A valid solution it to use the command \include. But I in this case I don&amp;rsquo;t want to include the .tex, I only want to be able to refer their labels.
This can be done using the xr package.</description>
    </item>
    
    <item>
      <title>Change the title of Table of Contents (ToC) in LaTeX</title>
      <link>http://212.71.254.23/blog/change-the-title-of-table-of-contents-toc-in-latex/</link>
      <pubDate>Wed, 13 Sep 2017 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/change-the-title-of-table-of-contents-toc-in-latex/</guid>
      <description>The steps to change the title of the table of contents (ToC) depends on if you are using the babel package or not.
Without babel The title of the table of contents can be changed using the command \contentsname. Let&amp;rsquo;s see a small example:
\documentclass{article} \renewcommand{\contentsname}{Index} % ToC will show &amp;quot;Index&amp;quot; instead of &amp;quot;Content&amp;quot; \begin{document} \tableofcontents \section{Section} \subsection{Subsection} \end{document} With babel When using babel package the name of the table of contents needs to be changed for the particular language used with babel.</description>
    </item>
    
    <item>
      <title>Spell-checking in Sublime Text 3</title>
      <link>http://212.71.254.23/blog/spell-checking-and-dictionaries-in-sublime-text-3/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/spell-checking-and-dictionaries-in-sublime-text-3/</guid>
      <description>I was a fan of the package Dictionaries but is seems that it is no available and that will not be re-included. The package&amp;rsquo;s page in package control is here, indicating that the package was removed.
Anyway, the package is in GitHub and it can be installed from the repository. The steps follows:
 Download the package as a ZIP file Open a terminal on your Downloads folder Unzip the file with unzip Dictionaries-master.</description>
    </item>
    
    <item>
      <title>Change key for toggle comment in Sublime Text 3</title>
      <link>http://212.71.254.23/blog/change-key-for-toggle-comment-in-sublime-text-3/</link>
      <pubDate>Wed, 06 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/change-key-for-toggle-comment-in-sublime-text-3/</guid>
      <description>I love Sublime Text 3 but I&amp;rsquo;m sued to Ctrl + Shift + C to toggle comment the current line or block of lines. The default behaviour of Sublime Text for commenting is:
{ &amp;quot;keys&amp;quot;: [&amp;quot;ctrl+/&amp;quot;], &amp;quot;command&amp;quot;: &amp;quot;toggle_comment&amp;quot;, &amp;quot;args&amp;quot;: { &amp;quot;block&amp;quot;: false } } { &amp;quot;keys&amp;quot;: [&amp;quot;ctrl+shift+/&amp;quot;], &amp;quot;command&amp;quot;: &amp;quot;toggle_comment&amp;quot;, &amp;quot;args&amp;quot;: { &amp;quot;block&amp;quot;: true } } I like it to behave like this:
{ &amp;quot;keys&amp;quot;: [&amp;quot;ctrl+shift+c&amp;quot;], &amp;quot;command&amp;quot;: &amp;quot;toggle_comment&amp;quot;, &amp;quot;args&amp;quot;: { &amp;quot;block&amp;quot;: false } } So, this lines means that the comments are done by line (not by block) and with the Ctrl + Shift + C key-binding.</description>
    </item>
    
    <item>
      <title>Gene-Enrichment in PsyGeNET&#39;s Main-Psychiatric-Disorders</title>
      <link>http://212.71.254.23/blog/gene-enrichment-in-psygenet-s-main-psychiatric-disorders/</link>
      <pubDate>Tue, 06 Jan 2015 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/gene-enrichment-in-psygenet-s-main-psychiatric-disorders/</guid>
      <description>PsyGeNET is a database that integrates information on psychiatric disorders and their genes (check its About page for more information). The current version of the database centered the information of three main psychiatric disorders: Alcoholism, Depression and Cocaine-Related-Disorders.
Currently the author of PsyGeNET, Alba GutiÃ©rrez, and me are developing an R package (PsyGeNET2R) to query the information stored into the database and to perform some analysis using this information. We thought that could be a good idea to perform an enrichment analysis on the three main psychiatric disorders given a list of genes of interest.</description>
    </item>
    
    <item>
      <title>Building a Compiler in .Net  (4 of 4)</title>
      <link>http://212.71.254.23/blog/building-a-compiler-in-net-4-of-4/</link>
      <pubDate>Sun, 01 Apr 2012 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/building-a-compiler-in-net-4-of-4/</guid>
      <description>This post is part of a series of 4. Here you have the links to each one:
 Building a Compiler in .Net (1 of 4) Building a Compiler in .Net (2 of 4) Building a Compiler in .Net (3 of 4) Building a Compiler in .Net (4 of 4)   Introduction In this forth post I am going to expose some utilities I have implemented for my version of VSLcompiler.</description>
    </item>
    
    <item>
      <title>Building a Compiler in .Net  (3 of 4)</title>
      <link>http://212.71.254.23/blog/building-a-compiler-in-net-3-of-4/</link>
      <pubDate>Mon, 13 Feb 2012 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/building-a-compiler-in-net-3-of-4/</guid>
      <description>This post is part of a series of 4. Here you have the links to each one:
 Building a Compiler in .Net (1 of 4) Building a Compiler in .Net (2 of 4) Building a Compiler in .Net (3 of 4) Building a Compiler in .Net (4 of 4)   Introduction In previous posts In this third post we will finish our compiler. In the last part ( number 4 ) we will talk about some educative improvements I&amp;rsquo;ve done to our compiler.</description>
    </item>
    
    <item>
      <title>Building a Compiler in .Net  (2 of 4)</title>
      <link>http://212.71.254.23/blog/building-a-compiler-in-net-2-of-4/</link>
      <pubDate>Wed, 25 Jan 2012 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/building-a-compiler-in-net-2-of-4/</guid>
      <description>This post is part of a series of 4. Here you have the links to each one:
 Building a Compiler in .Net (1 of 4) Building a Compiler in .Net (2 of 4) Building a Compiler in .Net (3 of 4) Building a Compiler in .Net (4 of 4)   Introduction In this second post we will implement the two first steps of a compiler: Scanner and Parser. Remember from part 1 a Scanner, also known as Lexical analyser, reads the characters from source code file and compose tokens.</description>
    </item>
    
    <item>
      <title>Building a Compiler in .Net  (1 of 4)</title>
      <link>http://212.71.254.23/blog/building-a-compiler-in-net-1-of-4/</link>
      <pubDate>Tue, 20 Dec 2011 00:00:00 +0200</pubDate>
      
      <guid>http://212.71.254.23/blog/building-a-compiler-in-net-1-of-4/</guid>
      <description>This post is part of a series of 4. Here you have the links to each one:
 Building a Compiler in .Net (1 of 4) Building a Compiler in .Net (2 of 4) Building a Compiler in .Net (3 of 4) Building a Compiler in .Net (4 of 4)   Introduction A compiler is a translator. As a translator can translate a piece of text, written in French, to German; a compiler translates a file written in a high level programming language to a low level programming language (like MicroJava or assembly).</description>
    </item>
    
  </channel>
</rss>
